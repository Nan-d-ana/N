import pandas as pd
import numpy as np
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
DATASET_DIR="C:\\Users\\HP\\Downloads\\archive (1)"
parquet_files=['Infiltration-Thursday-no-metadata.parquet','Portscan-Friday-no-metadata.parquet','WebAttacks-Thursday-no-metadata.parquet','DoS-Wednesday-no-metadata.parquet','DDoS-Friday-no-metadata.parquet','Bruteforce-Tuesday-no-metadata.parquet','Benign-Monday-no-metadata.parquet','Benign-Monday-no-metadata.parquet']
OUTPUT_DIR='processed_data'
os.makedirs(OUTPUT_DIR,exist_ok=True)
print("---Starting Data Loading from Parquet files---")
all_dfs=[]
for file_name in parquet_files:
    file_path=os.path.join(DATASET_DIR,file_name)
    if os.path.exists(file_path):
        print(f'Loading {file_name}....'):
        try:
            df_temp=pd.read_parquet(file_path)
            all_dfs.append(df_temp)
            print(f'Loaded {len(df_temp)} rows.')
        except Exception as e:
            print(f'Error loading {file_name}:{e}')
            print(f' Skipping {file_name}.')
    else:
        print(f'WARNING:File not found - {file_path}. Skipping.')