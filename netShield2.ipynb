{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72392a40-40c6-4813-b5b4-a377fc830381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier # Example model\n",
    "from sklearn.metrics import accuracy_score, classification_report # For evaluation\n",
    "import joblib # For saving the trained model\n",
    "import os # For path manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7acf1a1-d172-49e1-ba65-307405f9b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT_DIR = R\"D:\\intel\\processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6424a2af-fd14-4dbf-a728-747bc2f63341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filename of your dataset (it's directly in the root of the project folder)\n",
    "DATASET_FILENAME = 'final_netshield_cleaned_scaled_dataset.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e818812e-de90-475d-9b29-8ff8df34f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine the directory and filename to get the full path to the dataset\n",
    "DATASET_PATH = os.path.join(PROJECT_ROOT_DIR, DATASET_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d6a1d5-53cf-41a5-ac14-ccb8c5ff026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the path where the trained model will be saved\n",
    "# We'll create a 'trained_model' subfolder for this\n",
    "MODEL_SAVE_DIR = os.path.join(PROJECT_ROOT_DIR, 'trained_model')\n",
    "MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, 'network_intrusion_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ae18da-1237-479b-bcbc-c89358fce3b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 3: Loading the Cleaned Dataset ---\n",
      "Attempting to load dataset from: D:\\intel\\processed_data\\final_netshield_cleaned_scaled_dataset.parquet\n",
      "Dataset loaded successfully from: D:\\intel\\processed_data\\final_netshield_cleaned_scaled_dataset.parquet\n",
      "Dataset shape: (2596603, 79)\n",
      "First 5 rows of the dataset:\n",
      "   protocol  flow_duration  total_fwd_packets  total_backward_packets  \\\n",
      "0         6      -0.485030          -0.011998               -0.010310   \n",
      "1         6      -0.485033          -0.011998               -0.009399   \n",
      "2        17      -0.482243          -0.011998               -0.010310   \n",
      "3        17      -0.484001          -0.011998               -0.010310   \n",
      "4         0       2.619704           0.164207               -0.011221   \n",
      "\n",
      "   fwd_packets_length_total  bwd_packets_length_total  fwd_packet_length_max  \\\n",
      "0                 -0.062106                 -0.007681              -0.330554   \n",
      "1                 -0.062106                 -0.007681              -0.330554   \n",
      "2                 -0.057573                 -0.007662              -0.266827   \n",
      "3                 -0.057573                 -0.007662              -0.266827   \n",
      "4                 -0.062106                 -0.007681              -0.330554   \n",
      "\n",
      "   fwd_packet_length_min  fwd_packet_length_mean  fwd_packet_length_std  ...  \\\n",
      "0              -0.348984               -0.350344              -0.277703  ...   \n",
      "1              -0.348984               -0.350344              -0.277703  ...   \n",
      "2               0.439501               -0.101253              -0.277703  ...   \n",
      "3               0.439501               -0.101253              -0.277703  ...   \n",
      "4              -0.348984               -0.350344              -0.277703  ...   \n",
      "\n",
      "   active_mean  active_std  active_max  active_min  idle_mean  idle_std  \\\n",
      "0    -0.140546   -0.116329   -0.165416   -0.112365  -0.382225 -0.118763   \n",
      "1    -0.140546   -0.116329   -0.165416   -0.112365  -0.382225 -0.118763   \n",
      "2    -0.140546   -0.116329   -0.165416   -0.112365  -0.382225 -0.118763   \n",
      "3    -0.140546   -0.116329   -0.165416   -0.112365  -0.382225 -0.118763   \n",
      "4     2.412448    4.852934    4.190187   -0.112209  -0.000818  0.427598   \n",
      "\n",
      "   idle_max  idle_min   label  label_encoded  \n",
      "0 -0.387751 -0.367751  NORMAL              8  \n",
      "1 -0.387751 -0.367751  NORMAL              8  \n",
      "2 -0.387751 -0.367751  NORMAL              8  \n",
      "3 -0.387751 -0.367751  NORMAL              8  \n",
      "4  0.143864 -0.135487  NORMAL              8  \n",
      "\n",
      "[5 rows x 79 columns]\n",
      "\n",
      "Dataset information (data types, non-null values):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2596603 entries, 0 to 2596602\n",
      "Data columns (total 79 columns):\n",
      " #   Column                    Dtype  \n",
      "---  ------                    -----  \n",
      " 0   protocol                  int8   \n",
      " 1   flow_duration             float64\n",
      " 2   total_fwd_packets         float64\n",
      " 3   total_backward_packets    float64\n",
      " 4   fwd_packets_length_total  float64\n",
      " 5   bwd_packets_length_total  float64\n",
      " 6   fwd_packet_length_max     float64\n",
      " 7   fwd_packet_length_min     float64\n",
      " 8   fwd_packet_length_mean    float64\n",
      " 9   fwd_packet_length_std     float64\n",
      " 10  bwd_packet_length_max     float64\n",
      " 11  bwd_packet_length_min     float64\n",
      " 12  bwd_packet_length_mean    float64\n",
      " 13  bwd_packet_length_std     float64\n",
      " 14  flow_bytess               float64\n",
      " 15  flow_packetss             float64\n",
      " 16  flow_iat_mean             float64\n",
      " 17  flow_iat_std              float64\n",
      " 18  flow_iat_max              float64\n",
      " 19  flow_iat_min              float64\n",
      " 20  fwd_iat_total             float64\n",
      " 21  fwd_iat_mean              float64\n",
      " 22  fwd_iat_std               float64\n",
      " 23  fwd_iat_max               float64\n",
      " 24  fwd_iat_min               float64\n",
      " 25  bwd_iat_total             float64\n",
      " 26  bwd_iat_mean              float64\n",
      " 27  bwd_iat_std               float64\n",
      " 28  bwd_iat_max               float64\n",
      " 29  bwd_iat_min               float64\n",
      " 30  fwd_psh_flags             int8   \n",
      " 31  bwd_psh_flags             int8   \n",
      " 32  fwd_urg_flags             int8   \n",
      " 33  bwd_urg_flags             int8   \n",
      " 34  fwd_header_length         float64\n",
      " 35  bwd_header_length         float64\n",
      " 36  fwd_packetss              float64\n",
      " 37  bwd_packetss              float64\n",
      " 38  packet_length_min         float64\n",
      " 39  packet_length_max         float64\n",
      " 40  packet_length_mean        float64\n",
      " 41  packet_length_std         float64\n",
      " 42  packet_length_variance    float64\n",
      " 43  fin_flag_count            int8   \n",
      " 44  syn_flag_count            int8   \n",
      " 45  rst_flag_count            int8   \n",
      " 46  psh_flag_count            int8   \n",
      " 47  ack_flag_count            int8   \n",
      " 48  urg_flag_count            int8   \n",
      " 49  cwe_flag_count            int8   \n",
      " 50  ece_flag_count            int8   \n",
      " 51  downup_ratio              int16  \n",
      " 52  avg_packet_size           float64\n",
      " 53  avg_fwd_segment_size      float64\n",
      " 54  avg_bwd_segment_size      float64\n",
      " 55  fwd_avg_bytesbulk         int8   \n",
      " 56  fwd_avg_packetsbulk       int8   \n",
      " 57  fwd_avg_bulk_rate         int8   \n",
      " 58  bwd_avg_bytesbulk         int8   \n",
      " 59  bwd_avg_packetsbulk       int8   \n",
      " 60  bwd_avg_bulk_rate         int8   \n",
      " 61  subflow_fwd_packets       float64\n",
      " 62  subflow_fwd_bytes         float64\n",
      " 63  subflow_bwd_packets       float64\n",
      " 64  subflow_bwd_bytes         float64\n",
      " 65  init_fwd_win_bytes        float64\n",
      " 66  init_bwd_win_bytes        float64\n",
      " 67  fwd_act_data_packets      float64\n",
      " 68  fwd_seg_size_min          float64\n",
      " 69  active_mean               float64\n",
      " 70  active_std                float64\n",
      " 71  active_max                float64\n",
      " 72  active_min                float64\n",
      " 73  idle_mean                 float64\n",
      " 74  idle_std                  float64\n",
      " 75  idle_max                  float64\n",
      " 76  idle_min                  float64\n",
      " 77  label                     object \n",
      " 78  label_encoded             int64  \n",
      "dtypes: float64(57), int16(1), int64(1), int8(19), object(1)\n",
      "memory usage: 1.2+ GB\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Step 3: Loading the Cleaned Dataset ---\")\n",
    "print(f\"Attempting to load dataset from: {DATASET_PATH}\")\n",
    "try:\n",
    "    # Load the Parquet file into a pandas DataFrame using pyarrow engine\n",
    "    df = pd.read_parquet(DATASET_PATH, engine=\"pyarrow\")\n",
    "    print(f\"Dataset loaded successfully from: {DATASET_PATH}\")\n",
    "    print(f\"Dataset shape: {df.shape}\") # Shows (number of rows, number of columns)\n",
    "    print(\"First 5 rows of the dataset:\")\n",
    "    print(df.head()) # Displays the first 5 rows of your data\n",
    "\n",
    "    print(\"\\nDataset information (data types, non-null values):\")\n",
    "    df.info() # Provides a summary of your dataset's columns and data types\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Dataset file not found at: {DATASET_PATH}\")\n",
    "    print(\"Please double-check that the file name and the 'PROJECT_ROOT_DIR' are correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: An unexpected problem occurred while loading the dataset:\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(f\"Error message: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc() # Prints full technical details of the error\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a84510-5da9-4795-83d4-51a3e723a781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Step 5: Dividing Data into Training and Test Sets ---\n",
      "\n",
      "Shape of Features (X):(2596603, 77)\n",
      "Shape of Target (y):(2596603,)\n",
      "\n",
      "First 5 columns of X (Features):\n",
      "   protocol  flow_duration  total_fwd_packets  total_backward_packets  \\\n",
      "0         6      -0.485030          -0.011998               -0.010310   \n",
      "1         6      -0.485033          -0.011998               -0.009399   \n",
      "2        17      -0.482243          -0.011998               -0.010310   \n",
      "3        17      -0.484001          -0.011998               -0.010310   \n",
      "4         0       2.619704           0.164207               -0.011221   \n",
      "\n",
      "   fwd_packets_length_total  \n",
      "0                 -0.062106  \n",
      "1                 -0.062106  \n",
      "2                 -0.057573  \n",
      "3                 -0.057573  \n",
      "4                 -0.062106  \n"
     ]
    }
   ],
   "source": [
    "print(\"--- Starting Step 5: Dividing Data into Training and Test Sets ---\")\n",
    "all_columns=df.columns.tolist()\n",
    "features_to_exclude=['label','label_encoded']\n",
    "X_columns=[col for col in all_columns if col not in features_to_exclude]\n",
    "X=df[X_columns]\n",
    "y=df['label_encoded']\n",
    "print(f\"\\nShape of Features (X):{X.shape}\")\n",
    "print(f\"Shape of Target (y):{y.shape}\")\n",
    "print(\"\\nFirst 5 columns of X (Features):\")\n",
    "print(X.iloc[:, :5].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5022694c-41fc-4e60-8765-2326275f9fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of X_train (Training Features): (2077282, 77)\n",
      "Shape of X_test (Test Features): (519321, 77)\n",
      "Shape of y_train (Training Target): (2077282,)\n",
      "Shape of y_test (Test Target): (519321,)\n",
      "\n",
      "Class distribution in original dataset:\n",
      "label_encoded\n",
      "8     0.870964\n",
      "2     0.066566\n",
      "0     0.049301\n",
      "1     0.003961\n",
      "5     0.002284\n",
      "4     0.002074\n",
      "3     0.002013\n",
      "10    0.001240\n",
      "9     0.000753\n",
      "11    0.000566\n",
      "13    0.000251\n",
      "7     0.000014\n",
      "12    0.000008\n",
      "6     0.000004\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution in y_train:\n",
      "label_encoded\n",
      "8     0.870964\n",
      "2     0.066566\n",
      "0     0.049300\n",
      "1     0.003961\n",
      "5     0.002284\n",
      "4     0.002074\n",
      "3     0.002013\n",
      "10    0.001240\n",
      "9     0.000753\n",
      "11    0.000566\n",
      "13    0.000251\n",
      "7     0.000014\n",
      "12    0.000008\n",
      "6     0.000004\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution in y_test:\n",
      "label_encoded\n",
      "8     0.870964\n",
      "2     0.066566\n",
      "0     0.049301\n",
      "1     0.003961\n",
      "5     0.002284\n",
      "4     0.002074\n",
      "3     0.002014\n",
      "10    0.001240\n",
      "9     0.000753\n",
      "11    0.000566\n",
      "13    0.000252\n",
      "7     0.000013\n",
      "12    0.000008\n",
      "6     0.000004\n",
      "Name: proportion, dtype: float64\n",
      "--------------------------------------------------\n",
      "Data successfully split into training and test sets!\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42,stratify=y)\n",
    "print(f\"\\nShape of X_train (Training Features): {X_train.shape}\")\n",
    "print(f\"Shape of X_test (Test Features): {X_test.shape}\")\n",
    "print(f\"Shape of y_train (Training Target): {y_train.shape}\")\n",
    "print(f\"Shape of y_test (Test Target): {y_test.shape}\")\n",
    "print(\"\\nClass distribution in original dataset:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "print(\"\\nClass distribution in y_train:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nClass distribution in y_test:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "print(\"-\"*50)\n",
    "print(\"Data successfully split into training and test sets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afef94e-783c-412f-8820-1347cd294508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9b9a7-a57c-41f1-80e3-522896eae653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
